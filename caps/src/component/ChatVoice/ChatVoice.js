// src/components/ChatVoice/ChatVoice.js
import React, { useState, useRef, useEffect, useCallback } from 'react';
import './ChatVoice.css';

// ë§ˆí¬ë‹¤ìš´ ì œê±°
function stripMarkdown(text) {
  return text.replace(/\*\*(.*?)\*\*/g, '$1');
}

function ChatVoice() {
  const recognitionRef = useRef(null);
  const [isListening, setIsListening] = useState(false);
  const [messages, setMessages] = useState([]); // { role: 'user'|'assistant', content }

  // ë©”ì‹œì§€ ì¶”ê°€
  const addMessage = useCallback((role, content) => {
    setMessages(msgs => [...msgs, { role, content }]);
  }, []);

  // ìŒì„± ì¸ì‹ ì‹œì‘/ì¤‘ë‹¨ í•¨ìˆ˜
  const stopRecognition = useCallback(() => {
    recognitionRef.current?.stop();
    recognitionRef.current = null;
    setIsListening(false);
  }, []);




  // GPT í˜¸ì¶œ (history í¬í•¨)
  const sendToGpt = useCallback(async (userMsg) => {
    const res = await fetch(`${process.env.REACT_APP_BACKEND_URL}/chat`, {
    // const res = await fetch(`http://localhost:5000/chat`, {
      method: 'POST',
      headers: { 'Content-Type': 'application/json' },
      body: JSON.stringify({
        history: messages,
        message: userMsg
      })
    });
    const { reply } = await res.json();
    return reply;
  }, [messages]);

  // TTS ì¬ìƒ (ì¤‘ê°„ ëŠê¸° ê°ì§€ + ì¸ì‹ ì¬ì‹œì‘)
  const speak = useCallback((rawText, onEnd) => {
    // 1) ë‹µë³€ ì¬ìƒ ì „ ì¸ì‹ ì¤‘ë‹¨
    stopRecognition();

    // 2) ê¸°ì¡´ TTSê°€ ìˆìœ¼ë©´ ëª¨ë‘ ì·¨ì†Œ
    window.speechSynthesis.cancel();

    // **ë§ˆí¬ë‹¤ìš´ ë³„í‘œ ì œê±°**
    const cleanText = stripMarkdown(rawText);

    // 3) ìƒˆ Utterance ìƒì„±
    const utter = new SpeechSynthesisUtterance(cleanText);
    utter.lang = 'ko-KR';
    // ì¬ìƒì´ ì™„ì „íˆ ëë‚˜ë©´ onEnd() í˜¸ì¶œ
    utter.onend = onEnd;
    window.speechSynthesis.speak(utter);

    // 4) VAD(Voice Activity Detection) ì„¤ì •
    navigator.mediaDevices.getUserMedia({ audio: true }).then(stream => {
      const audioCtx = new AudioContext();
      const analyser = audioCtx.createAnalyser();
      const source = audioCtx.createMediaStreamSource(stream);
      source.connect(analyser);

      const data = new Uint8Array(analyser.frequencyBinCount);
      const VAD_THRESHOLD = 35; // RMS ì„ê³„ê°’ (ì‹¤í™˜ê²½ì— ë§ì¶° ì¡°ì •)

      function detect() {
        analyser.getByteTimeDomainData(data);
        let sum = 0;
        for (let v of data) sum += (v - 128) ** 2;
        const rms = Math.sqrt(sum / data.length);

        // ì‚¬ìš©ìê°€ ë§ì„ ì‹œì‘í•˜ë©´ TTS ì¦‰ì‹œ ì·¨ì†Œ
        if (rms > VAD_THRESHOLD) {
          window.speechSynthesis.cancel();
          audioCtx.close();
          onEnd();
        }
        // TTS ì¬ìƒ ì¤‘ì´ë©´ ê³„ì† ëª¨ë‹ˆí„°ë§
        else if (window.speechSynthesis.speaking) {
          requestAnimationFrame(detect);
        }
        // TTSê°€ ëë‚˜ë©´ ì²­ì·¨ ì¢…ë£Œ
        else {
          audioCtx.close();
        }
      }

      detect();
    });
  }, [stopRecognition]);

  // ìŒì„± ì¸ì‹ ì‹œì‘
  const startRecognition = useCallback(() => {
    const SR = window.SpeechRecognition || window.webkitSpeechRecognition;
    if (!SR) {
      alert('ì´ ë¸Œë¼ìš°ì €ëŠ” ìŒì„± ì¸ì‹ì„ ì§€ì›í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.');
      return;
    }

    const rec = new SR();
    rec.lang = 'ko-KR';
    rec.interimResults = true;
    rec.continuous = true;

    // í›„ë³´ ë¬¸ì¥ ê°œìˆ˜
    rec.maxAlternatives = 7;

    rec.onstart = () => setIsListening(true);
    rec.onend   = () => setIsListening(false);

    rec.onerror = (e) => {
      console.error('Recognition error:', e.error);
      setIsListening(false);
    };

    rec.onresult = async (e) => {
      const last = e.results[e.results.length - 1];
      if (!last.isFinal) return;

      // confidence ìˆœ ì •ë ¬
      const alts = Array.from(last).sort((a,b) => b.confidence - a.confidence);
      const best = alts[0];
      const text = best.transcript.trim();

      // confidence ë° ìµœì†Œ ê¸¸ì´ í•„í„°ë§
      if (best.confidence < 0.85 || text.length < 3) {
        return;
      }

      // ë°œí™” ì™„ë£Œ íŒë‹¨ â†’ GPT ìš”ì²­
      rec.stop();
      addMessage('user', text);
      const reply = await sendToGpt(text);
      addMessage('assistant', reply);

      // TTS ì¶œë ¥ í›„ ë‹¤ì‹œ ì²­ì·¨ ëª¨ë“œ
      speak(reply, startRecognition);
    };

    recognitionRef.current = rec;
    rec.start();
  }, [addMessage, sendToGpt, speak]);

  // ë§ˆìš´íŠ¸ ì‹œ ìë™ ì‹œì‘, ì–¸ë§ˆìš´íŠ¸ ì‹œ ì •ë¦¬
  useEffect(() => {
    startRecognition();
    return () => stopRecognition();
  }, [startRecognition, stopRecognition]);

  return (
    <div className="chat-voice">

      <div className="messages">
        {messages.map((m,i) =>
          <div key={i} className={m.role}>{m.content}</div>
        )}
      </div>
      <button
        className="voice-button"
        onClick={() => isListening ? stopRecognition() : startRecognition()}
      >
        {isListening ? 'â¹ ì¼ì‹œì •ì§€' : 'ğŸ¤ ëŒ€í™” ì‹œì‘'}
      </button>
    </div>
  );
}

export default ChatVoice;
